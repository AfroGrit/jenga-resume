{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib\n",
    "%matplotlib inline\n",
    "import pickle\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "manga = 'https://myanimelist.net/topmanga.php'\n",
    "\n",
    "headers = {\n",
    "    'Accept-Language': 'en',\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3',\n",
    "    'X-FORWARDED-FOR': '2.21.184.0'\n",
    "}\n",
    "\n",
    "response = requests.get(manga, headers=headers)\n",
    "print(response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "mangasoup = BeautifulSoup(response.text, \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mangasoup.find_all('a')\n",
    "# mangasoup.find_all('h3', attrs={'class': \"manga_h3\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'?limit=50'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mangasoup.find_all('a', attrs={'class': 'next'})[0]['href']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "\n",
    "def get_links_to_movies(soup):\n",
    "    h3s = soup.find_all('h3', attrs={'class': \"manga_h3\"})\n",
    "    movie_links = {el.find('a').text: el.find('a')['href'] for el in h3s}\n",
    "    return movie_links    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_link_to_next_page(soup):\n",
    "    links = soup.find_all('a', attrs={'class': 'next'})\n",
    "    if len(links) == 0:\n",
    "        return None\n",
    "    else:\n",
    "        link = links[0]['href']\n",
    "        return link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_all_links(url):\n",
    "#     headers = {'Accept-Language': 'en',\n",
    "#                'X-FORWARDED-FOR': '2.21.184.0'}\n",
    "    \n",
    "#     all_movies_links = {}\n",
    "    \n",
    "#     while True:\n",
    "#         response = requests.get(url, headers=headers)\n",
    "#         assert response.status_code == 200\n",
    "#         soup = BeautifulSoup(response.text)\n",
    "#         movie_links = get_links_to_movies(soup)\n",
    "#         movie_links = {movie: urllib.parse.urljoin(url, movie_link) for (movie, movie_link) in movie_links.items()}\n",
    "        \n",
    "#         all_movies_links.update(movie_links)\n",
    "#         print(f'number of links so far: { len(all_movies_links)}')\n",
    "#         link = get_link_to_next_page(soup)\n",
    "#         if not link:\n",
    "#             return all_movies_links\n",
    "#         url = urllib.parse.urljoin(url, link)\n",
    "#         time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_all_links(url, max_links=30000):\n",
    "    headers = {\n",
    "        'Accept-Language': 'en',\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3',\n",
    "        'X-FORWARDED-FOR': '2.21.184.0'\n",
    "    }\n",
    "    \n",
    "    all_movies_links = {}\n",
    "    \n",
    "    # Initialize tqdm progress bar\n",
    "    pbar = tqdm(total=max_links, desc=\"Collecting movie links\")\n",
    "    \n",
    "    while True:\n",
    "        response = requests.get(url, headers=headers)\n",
    "        assert response.status_code == 200\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        movie_links = get_links_to_movies(soup)\n",
    "        movie_links = {movie: urllib.parse.urljoin(url, movie_link) for (movie, movie_link) in movie_links.items()}\n",
    "        \n",
    "        new_links_count = len(movie_links)\n",
    "        all_movies_links.update(movie_links)\n",
    "        \n",
    "        # Update progress bar\n",
    "        pbar.update(min(new_links_count, max_links - pbar.n))\n",
    "        \n",
    "        if len(all_movies_links) >= max_links:\n",
    "            pbar.close()\n",
    "            print(f'Reached {max_links} links. Stopping.')\n",
    "            return dict(list(all_movies_links.items())[:max_links])\n",
    "        \n",
    "        link = get_link_to_next_page(soup)\n",
    "        if not link:\n",
    "            pbar.close()\n",
    "            return all_movies_links\n",
    "        url = urllib.parse.urljoin(url, link)\n",
    "        time.sleep(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting movie links: 100%|██████████| 30000/30000 [28:41<00:00, 17.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached 30000 links. Stopping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "all_manga_links = get_all_links(manga)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('all_manga_links', 'wb') as f:\n",
    "    pickle.dump(all_manga_links, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "resume",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
